{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9_6dFdkHGZDH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn, optim, tensor\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchtext\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator, Vectors\n",
        "import pandas as pd\n",
        "import time\n",
        "import numpy as np\n",
        "import torch.nn.functional as TF\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import json\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-PeU4jiKUsl"
      },
      "source": [
        "## Load English & Chinese pretrained embedding from Tecent AI Lab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kprOMoRxHi_a",
        "outputId": "94ecb317-41de-4379-9ebe-a7fc915cf2fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZFKHmIR1INmT"
      },
      "outputs": [],
      "source": [
        "# Load pretrained model from Tencent\n",
        "from gensim.models import KeyedVectors\n",
        "# 100-dim en file\n",
        "wv_from_text_en = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/LING111 autoencoder/tencent-ailab-embedding-en-d100-v0.1.0-s\", binary=False)\n",
        "\n",
        "# 100-dim zh file\n",
        "wv_from_text_zh = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/LING111 autoencoder/tencent-ailab-embedding-zh-d100-v0.2.0-s.txt\", binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "YBuLiUzUKLgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b7d69b7-3ca3-4700-e7b8-179b3983eb91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 10 words in the vocabulary are: ['</s>', '，', ',', '的', '。', '、', '了', '：', '“', '”']\n",
            "The index for the Chinese word '的' is: 3\n"
          ]
        }
      ],
      "source": [
        "# Define Chinese inputs for the model\n",
        "\n",
        "# vocab_zh contains all the Chinese words in the dataset\n",
        "vocab_zh      = wv_from_text_zh.index_to_key\n",
        "vocab_size_zh = len(vocab_zh)\n",
        "print(\"The first 10 words in the vocabulary are:\", vocab_zh[:10])\n",
        "\n",
        "# word_to_index is the map between Chinese words and its indeces {'的'：3}\n",
        "word_to_index_zh = wv_from_text_zh.key_to_index\n",
        "print(\"The index for the Chinese word '的' is:\", word_to_index_zh['的'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n3y2GXcXKrT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd03c65d-4b07-40d3-bbac-5871e6008961"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 10 words in the vocabulary are: ['%2c', '.', '%22', 'and', 'of', '%3a', 'a', 'in', '/', '%29']\n",
            "The index for the English word 'cannot' is: 1202\n"
          ]
        }
      ],
      "source": [
        "# Define English inputs for the model\n",
        "\n",
        "# vocab_en contains all the English words in the dataset\n",
        "vocab_en      = wv_from_text_en.index_to_key\n",
        "vocab_size_en = len(vocab_en)\n",
        "print(\"The first 10 words in the vocabulary are:\", vocab_en[:10])\n",
        "\n",
        "# word_to_index is the map between English words and its indeces {'yes'：3}\n",
        "word_to_index_en = wv_from_text_en.key_to_index\n",
        "print(\"The index for the English word 'cannot' is:\", word_to_index_en[\"cannot\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qvV_FMo842f"
      },
      "source": [
        "## Load Golden Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3EYK0iGN_t4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823ca8fa-7707-494b-cf91-3c19d2253703"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese translation for universal is 普遍\n"
          ]
        }
      ],
      "source": [
        "# Load the golden set\n",
        "with open(\"/content/drive/MyDrive/LING111 autoencoder/full_golden_set.json\", encoding=\"utf-8-sig\") as in_file:\n",
        "  # returns JSON object as a dictionary\n",
        "    golden_set = json.load(in_file)\n",
        "\n",
        "# Closing file\n",
        "in_file.close()\n",
        "\n",
        "word = \"universal\"\n",
        "print(\"Chinese translation for {} is {}\".format(word, golden_set[word][0]))\n",
        "\n",
        "en_vocab = golden_set.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "b91QIGEIHuV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfa632ad-17f0-4fff-e154-66f7b867b2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 8063 unique English words in our golden set\n"
          ]
        }
      ],
      "source": [
        "# en_vocab_list is list of unique English words in golden set\n",
        "gold_en_list = list(golden_set.keys())\n",
        "\n",
        "# length of English vocabulary\n",
        "gold_en_size = len(gold_en_list)\n",
        "print(\"There are\", gold_en_size, \"unique English words in our golden set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kW8YfhOcKrdy"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "FVGS3mtOR43B"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(4)\n",
        "np.random.seed(4)\n",
        "random.seed(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MwYidapPJsoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13b9ab52-9a80-450a-f51e-90449645e213"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 6374 training data and 2125 testing data\n"
          ]
        }
      ],
      "source": [
        "# Define the training & testing data to pass for the custom dataset\n",
        "# train_data is in the form of a dictionary that contains\n",
        "# corresponding pair of English word (data) and Chinese\n",
        "# translation (label)\n",
        "# Last 15% of the dataset is testing data\n",
        "\n",
        "train_data = {}\n",
        "test_data  = {}\n",
        "en_list_train = []\n",
        "zh_list_train = []\n",
        "en_list_test = []\n",
        "zh_list_test = []\n",
        "en_list = []\n",
        "zh_list = []\n",
        "en_index_train = []\n",
        "zh_index_train = []\n",
        "en_index_test = []\n",
        "zh_index_test = []\n",
        "\n",
        "# Shuffle the data before splitting it into train & test samples\n",
        "random.shuffle(gold_en_list)\n",
        "\n",
        "# Make\n",
        "\n",
        "# Make copies of english words that have more than 1 Chinese translation\n",
        "for en in gold_en_list:\n",
        "    # en_list.append(en)\n",
        "    # zhs = []\n",
        "    for zh in golden_set[en]:\n",
        "      en_list.append(en)\n",
        "      zh_list.append(zh)\n",
        "    #     zhs.append(zh)\n",
        "    # zh_list.append(zhs)\n",
        "\n",
        "# Last 15% of data is allocated as testing samples\n",
        "cutoff = int(len(en_list) * 0.75)\n",
        "en_list_train = en_list[:cutoff]\n",
        "zh_list_train = zh_list[:cutoff]\n",
        "en_list_test  = en_list[cutoff:]\n",
        "zh_list_test  = zh_list[cutoff:]\n",
        "print(\"There are\", len(en_list_train), \"training data and\", len(en_list_test), \"testing data\")\n",
        "\n",
        "# The real training data are the words that exist in the Tecent AI dataset\n",
        "\n",
        "en_index_train = [(i, word_to_index_en[i]) for i, j in zip(en_list_train, zh_list_train) if i in word_to_index_en and j in word_to_index_zh]\n",
        "\n",
        "\n",
        "\n",
        "zh_index_train = [(i, word_to_index_zh[i]) for i, j in zip(zh_list_train, en_list_train) if i in word_to_index_zh and j in word_to_index_en]\n",
        "en_index_test = [(i, word_to_index_en[i]) for i, j in zip(en_list_test, zh_list_test) if i in word_to_index_en and j in word_to_index_zh]\n",
        "\n",
        "zh_index_test = [(i, word_to_index_zh[i]) for i, j in zip(zh_list_test, en_list_test) if i in word_to_index_zh and j in word_to_index_en]\n",
        "\n",
        "# train_engs = []\n",
        "# en_index_train = []\n",
        "# for en, zhs in zip(en_list_train, zh_list_train):\n",
        "#     indices = []\n",
        "#     count = 0\n",
        "#     for word in zhs:\n",
        "#         if en in word_to_index_en and word in word_to_index_zh:\n",
        "#             count += 1\n",
        "#     if count != 0:\n",
        "#         train_engs.append(en)\n",
        "#         en_index_train.append((en, word_to_index_en[en]))\n",
        "\n",
        "# zh_index_train = []\n",
        "# for zhs, en in zip(zh_list_train, en_list_train):\n",
        "#     indices = []\n",
        "#     for word in zhs:\n",
        "#         if word in word_to_index_zh and en in word_to_index_en:\n",
        "#             indices.append((word, word_to_index_zh[word]))\n",
        "#     if en in train_engs:\n",
        "#         zh_index_train.append(indices)\n",
        "\n",
        "# test_engs = []\n",
        "# en_index_test = []\n",
        "# for en, zhs in zip(en_list_test, zh_list_test):\n",
        "#     indices = []\n",
        "#     count = 0\n",
        "#     for word in zhs:\n",
        "#         if en in word_to_index_en and word in word_to_index_zh:\n",
        "#             count += 1\n",
        "#     if count != 0:\n",
        "#         test_engs.append(en)\n",
        "#         en_index_test.append((en, word_to_index_en[en]))\n",
        "\n",
        "# zh_index_test = []\n",
        "# for zhs, en in zip(zh_list_test, en_list_test):\n",
        "#     indices = []\n",
        "#     for word in zhs:\n",
        "#         if word in word_to_index_zh and en in word_to_index_en:\n",
        "#             indices.append((word, word_to_index_zh[word]))\n",
        "#     if en in test_engs:\n",
        "#         zh_index_test.append(indices)\n",
        "\n",
        "train_data[\"data\"]  = en_index_train\n",
        "train_data[\"label\"] = zh_index_train\n",
        "test_data[\"data\"]   = en_index_test\n",
        "test_data[\"label\"]  = zh_index_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WgGQAP1xC70b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ca6a49-32df-41f9-d19c-7d39dd807d63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 6188 training data present in the Tencent AI dataset\n",
            "There are 2048 testing data present in the Tencent AI dataset\n"
          ]
        }
      ],
      "source": [
        "print(\"There are {} training data present in the Tencent AI dataset\".format(len(train_data[\"data\"])))\n",
        "print(\"There are {} testing data present in the Tencent AI dataset\".format(len(test_data[\"data\"])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-1ABDwtRDONp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a10228a-8b0a-4d6f-e06c-e5bf8aa05053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training data and label is the same True\n",
            "The number of testing data and label is the same True\n"
          ]
        }
      ],
      "source": [
        "print(\"The number of training data and label is the same\", len(train_data[\"data\"]) == len(train_data[\"label\"]))\n",
        "print(\"The number of testing data and label is the same\", len(test_data[\"data\"]) == len(test_data[\"label\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bDKhA7K1E5fY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8607822-0193-4cbc-fe0c-cab1609e60bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('analytic', 44911), ('解析', 4224))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "train_data[\"data\"][10], train_data[\"label\"][10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpNZBD5EKzRk"
      },
      "source": [
        "## Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rRK20QtaN7ln"
      },
      "outputs": [],
      "source": [
        "# Define dataset to load to dataloader\n",
        "class TrainData(Dataset):\n",
        "\n",
        "    def __init__(self, data):\n",
        "        \"\"\"Loads the data from the pretrained model\"\"\"\n",
        "        self.data    = data\n",
        "        self.en_list = self.data[\"data\"]\n",
        "        self.zh_list = self.data[\"label\"]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"Returns the datapoint at a given index\"\"\"\n",
        "        en_index = self.en_list[idx][1]\n",
        "        zh_index = self.zh_list[idx][1]\n",
        "        sample = {\"en_index\": en_index, \"zh_index\": zh_index}\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Returns the number of datapoints in the dataset\"\"\"\n",
        "        return len(self.data[\"data\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "t__SJcYC-kmJ"
      },
      "outputs": [],
      "source": [
        "def collate_batch(batch):\n",
        "    \"\"\"Converts a batch of data into packed PyTorch tensor format\n",
        "    \"\"\"\n",
        "    # Initialize lists that separate out the 3 components\n",
        "    en_index_list  = list()\n",
        "    zh_index_list  = list()\n",
        "\n",
        "    for pair in batch:\n",
        "        en_index = pair[\"en_index\"]\n",
        "        zh_index = pair[\"zh_index\"]\n",
        "        # Convert to PyTorch format\n",
        "        # Add converted data to separate component lists\n",
        "        en_index_list.append(en_index)\n",
        "        zh_index_list.append(zh_index)\n",
        "\n",
        "    # Convert to mini-batch tensors\n",
        "    en_index_tensor = torch.tensor(en_index_list).to(torch.int64)\n",
        "    zh_index_tensor = torch.tensor(zh_index_list).to(torch.int64)\n",
        "\n",
        "    return (en_index_tensor, zh_index_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "or-3iU-GN99W"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "training_data = TrainData(train_data)\n",
        "testing_data  = TrainData(test_data)\n",
        "train_dataloader = DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=collate_batch)\n",
        "test_dataloader  = DataLoader(dataset=testing_data,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True,\n",
        "                              collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jRncFCQo5P9O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04b177f5-427f-4618-ac7a-eda691d5cc85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('compressed', '压缩')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "next(iter(train_dataloader))\n",
        "vocab_en[17362], vocab_zh[9060]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "5ZwEOPCJPg08"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def timeSince(since):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol40urenK3Qu"
      },
      "source": [
        "## Learning rate schedulor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "bgx6ES1_PiN4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "outputId": "f20c0f96-9845-41dd-9de1-d56c9db29257"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Cosine Scheduler')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# credit: https://d2l.ai/chapter_optimization/lr-scheduler.html\n",
        "class CosineScheduler:\n",
        "    def __init__(self, max_update, base_lr=0.01, final_lr=0,\n",
        "               warmup_steps=0, warmup_begin_lr=0):\n",
        "        self.base_lr_orig = base_lr\n",
        "        self.max_update = max_update\n",
        "        self.final_lr = final_lr\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.warmup_begin_lr = warmup_begin_lr\n",
        "        self.max_steps = self.max_update - self.warmup_steps\n",
        "\n",
        "    def get_warmup_lr(self, epoch):\n",
        "        increase = (self.base_lr_orig - self.warmup_begin_lr) \\\n",
        "                       * float(epoch) / float(self.warmup_steps)\n",
        "        return self.warmup_begin_lr + increase\n",
        "\n",
        "    def __call__(self, epoch):\n",
        "        if epoch < self.warmup_steps:\n",
        "            return self.get_warmup_lr(epoch)\n",
        "        if epoch <= self.max_update:\n",
        "            self.base_lr = self.final_lr + (\n",
        "                self.base_lr_orig - self.final_lr) * (1 + math.cos(\n",
        "                math.pi * (epoch - self.warmup_steps) / self.max_steps)) / 2\n",
        "        return self.base_lr\n",
        "\n",
        "scheduler = CosineScheduler(max_update=50, base_lr=0.3, final_lr=0.001)\n",
        "num_epochs = 50\n",
        "sch = [scheduler(t) for t in range(num_epochs)]\n",
        "xtrain = np.arange(num_epochs)\n",
        "plt.plot(xtrain, sch)\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.title(\"Cosine Scheduler\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbY17T_cLELe"
      },
      "source": [
        "## Model Definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5C3hgDlzTwna",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49a76ac0-4ce1-4d39-e909-33b8c5f99272"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y9YK7_zoTxq9"
      },
      "outputs": [],
      "source": [
        "class ZhZhAutoencoderTW(nn.Module):\n",
        "    \"\"\"\n",
        "    Autoencoder to learn the weights connecting Chinese\n",
        "    embeddings back to one-hot vectors. Initialize the\n",
        "    weights connecting the embeddings and one-hot vectors\n",
        "    with the transpose of the weights from the Tecent\n",
        "    pretrained model, connecting the one-hot vector and\n",
        "    embedding, to speed up training.\n",
        "    \"\"\"\n",
        "    def __init__(self, pretrained, vocab):\n",
        "        super(ZhZhAutoencoderTW, self).__init__()\n",
        "\n",
        "        # Save the pretrained embedding within the model\n",
        "        # load pretrained embeddings and freeze them\n",
        "        self.weights    = torch.FloatTensor(pretrained.vectors)\n",
        "        self.encoder    = nn.Embedding.from_pretrained(self.weights, freeze = True)\n",
        "\n",
        "        # Make a copy of the pretrained weights and use them in the following layers\n",
        "        copy_pretrained = copy.deepcopy(pretrained)\n",
        "        self.copyweight = torch.FloatTensor(copy_pretrained.vectors)\n",
        "        self.decoder    = nn.Parameter(self.copyweight.t())\n",
        "        self.vocab      = vocab\n",
        "\n",
        "    def forward(self, text):\n",
        "        \"\"\"The pipeline that takes input values through the network\"\"\"\n",
        "        # Find the embeddings for text\n",
        "        trained_embed = self.encoder(text)\n",
        "\n",
        "        # Turn embedding back to one-hot\n",
        "        one_hot       = trained_embed @ self.decoder\n",
        "\n",
        "        return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KP2S76SWPnnQ"
      },
      "outputs": [],
      "source": [
        "# Autoencoder to learn the weights connecting embeddings back to one-hot vectors\n",
        "class EnZhAutoencoderNonHidden(nn.Module):\n",
        "\n",
        "    def __init__(self, pretrained_en, pretrained_zh, vocab_en, vocab_zh):\n",
        "        super(EnZhAutoencoderNonHidden, self).__init__()\n",
        "\n",
        "        # Save the pretrained English embedding from Tencent within the model\n",
        "        # load pretrained embeddings and freeze them\n",
        "        self.weights_en = torch.FloatTensor(pretrained_en.vectors)\n",
        "        self.encoder    = nn.Embedding.from_pretrained(self.weights_en, freeze = True)\n",
        "\n",
        "        # Load the pretrained weights from zhzhautoencoder\n",
        "        # Use the pretrained weights to map Chinese embedding to one-hot\n",
        "        # ***** use the tranpose!!!\n",
        "        self.zh_weights = pretrained_zh\n",
        "        self.decoder    = nn.Parameter(self.zh_weights, requires_grad=False)\n",
        "\n",
        "        # Load the Chinese & English vocab\n",
        "        self.vocab_en   = vocab_en\n",
        "        self.vocab_zh   = vocab_zh\n",
        "\n",
        "        # Weights for English to Chinese embeddings\n",
        "        self.entozh = nn.Linear(100, 100)\n",
        "\n",
        "    def forward(self, text):\n",
        "        \"\"\"The pipeline that takes input values through the network\"\"\"\n",
        "        # Find the English embedding\n",
        "        eng_emb = self.encoder(text)\n",
        "\n",
        "        # Pass the English embedding through hidden layer\n",
        "        # zh_emb  = self.hidden(eng_emb) # torch.Size([256, 100])\n",
        "\n",
        "        # Find the corresponding index of Chinese word for\n",
        "        # the English embedding decoder: torch.Size([100, 2000000])\n",
        "        zh_emb = self.entozh(eng_emb)\n",
        "\n",
        "        one_hot = zh_emb @ self.decoder\n",
        "\n",
        "        return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iVa1-sMupC75"
      },
      "outputs": [],
      "source": [
        "def train(model, file, modelFilePath, num_epochs, optimizer, criterion):\n",
        "    # Training\n",
        "    avg_loss = []\n",
        "    losses = 0\n",
        "    start = time.time()\n",
        "    print(\"Start Batch Size =\", batch_size, file=open(file, 'a'))\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        losses = 0\n",
        "        correct_test = 0\n",
        "        total_test = 0\n",
        "        accuracy_test = []\n",
        "        for i, (en_index, zh_index) in enumerate(train_dataloader):\n",
        "            # Clear gradients w.r.t. parameters\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Move inputs & outputs to cuda\n",
        "            en_index = en_index.to(device)\n",
        "            zh_index = zh_index.to(device)\n",
        "\n",
        "            # Forward pass to get output/logits\n",
        "            outputs_train = model(en_index)\n",
        "\n",
        "            # Get predictions from the maximum value\n",
        "            prob = TF.softmax(outputs_train, dim=1)\n",
        "            # top_three = torch.topk(prob, 3, dim=1).indices\n",
        "            # # print(top_three)\n",
        "            index = torch.argmax(prob, dim=1)\n",
        "            # print(index)\n",
        "\n",
        "\n",
        "            # Total number of labels\n",
        "            total_test += en_index.size(0)\n",
        "\n",
        "            # Total correct predictions\n",
        "            # correct = zh_index.tolist()\n",
        "            # preds = top_three.tolist()\n",
        "\n",
        "            # for i in range(len(preds)):\n",
        "            #     if correct[i] in preds[i]:\n",
        "            #         correct_test += 1\n",
        "\n",
        "            correct_test += torch.sum(index==zh_index).item()\n",
        "\n",
        "            # Calculate Loss: softmax --> cross entropy loss\n",
        "            loss = criterion(outputs_train, zh_index)\n",
        "            losses += loss.item()\n",
        "\n",
        "            # Getting gradients w.r.t. parameters\n",
        "            loss.backward()\n",
        "\n",
        "            # Updating parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        print(correct_test)\n",
        "        print(total_test)\n",
        "        cur_accuracy = 100 * correct_test / total_test\n",
        "        accuracy_test.append(cur_accuracy)\n",
        "        print(f'Training accuracy at epoch {epoch}: %.15f' % (cur_accuracy))\n",
        "\n",
        "        avg = losses / len(train_dataloader.dataset)\n",
        "        avg_loss.append(avg)\n",
        "\n",
        "        # Test the model every 10 epochs\n",
        "        if epoch % 10 == 0 or epoch==49:\n",
        "            test(model, file)\n",
        "            model.train()\n",
        "            torch.save(model.state_dict(), f\"/content/drive/MyDrive/LING111 autoencoder/enzh_nonhidden {epoch}.pt\")\n",
        "\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = scheduler(epoch)\n",
        "            print(\"Learning rate is now\", param_group['lr'])\n",
        "\n",
        "        print('%s (%d %d%%) %.15f' % (timeSince(start), epoch, epoch / num_epochs * 100, avg))\n",
        "        torch.save(model.state_dict(), modelFilePath)\n",
        "\n",
        "    print(\"Finish training!\")\n",
        "    return avg_loss\n",
        "\n",
        "def test(model, file):\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "    accuracy_test = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Iterate through test dataset\n",
        "        for i, (en_index, zh_index) in enumerate(test_dataloader):\n",
        "\n",
        "            # Move inputs & outputs to cuda\n",
        "            en_index = en_index.to(device)\n",
        "            zh_index = zh_index.to(device)\n",
        "\n",
        "            # Forward pass only to get logits/output\n",
        "            outputs_test = model(en_index)\n",
        "\n",
        "            # Get predictions from the maximum value\n",
        "            prob = TF.softmax(outputs_test, dim=1)\n",
        "            # top_three = torch.topk(prob, 3).indices\n",
        "            index = torch.argmax(prob, dim=1)\n",
        "\n",
        "            # print(top_three)\n",
        "            # print(index)\n",
        "\n",
        "            # correct = zh_index.tolist()\n",
        "            # preds = top_three.tolist()\n",
        "\n",
        "            # for i in range(len(preds)):\n",
        "            #     if correct[i] in preds[i]:\n",
        "            #         correct_test += 1\n",
        "\n",
        "            # Total number of labels\n",
        "            total_test += en_index.size(0)\n",
        "\n",
        "            # Total correct predictions\n",
        "\n",
        "            correct_test += torch.sum(index==zh_index).item()\n",
        "        cur_accuracy = 100 * correct_test / total_test\n",
        "        accuracy_test.append(cur_accuracy)\n",
        "        # Print Loss\n",
        "        print('Test accuracy: %.15f' % (cur_accuracy))\n",
        "\n",
        "        return  accuracy_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "CPYUeFaxViCw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec35fb66-b4da-4268-b2e2-db4ccd854c84"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "model_zhzh = ZhZhAutoencoderTW(wv_from_text_zh, vocab_zh).to(device)\n",
        "model_zhzh_weight = torch.load('/content/drive/MyDrive/LING111 autoencoder/ling111_project_wt.pt', map_location='cuda:0')\n",
        "model_zhzh.load_state_dict(model_zhzh_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5cDrAKhLOF3",
        "outputId": "91331b78-2661-407e-f42c-f3100f46ae9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weights in the ZhZhAutoencoderTW model are odict_keys(['decoder', 'encoder.weight'])\n"
          ]
        }
      ],
      "source": [
        "# Extract the decoder weights to use in the final autoencoder\n",
        "print(\"The weights in the ZhZhAutoencoderTW model are\", model_zhzh.state_dict().keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WX9OZ0zPV-Wx"
      },
      "outputs": [],
      "source": [
        "model_enzh_decoder = model_zhzh.decoder.clone()\n",
        "model_enzh = EnZhAutoencoderNonHidden(wv_from_text_en, model_enzh_decoder, vocab_en, vocab_zh).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The weights in the EnZhAutoencoder model are\", model_enzh.state_dict().keys())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFhB7WwokzoV",
        "outputId": "a10c24e0-b3bb-4d4a-8994-945bce2477a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The weights in the EnZhAutoencoder model are odict_keys(['decoder', 'encoder.weight', 'entozh.weight', 'entozh.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TaeFKCz4u5FR"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_enzh.parameters(), lr=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl5zAX6DREh1",
        "outputId": "0a3d4b9b-f106-4217-ca1b-f7fc334ab8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14\n",
            "6188\n",
            "Training accuracy at epoch 0: 0.226244343891403\n",
            "Test accuracy: 0.634765625000000\n",
            "Learning rate is now 0.3\n",
            "0m 46s (0 0%) 28.978229752030771\n",
            "28\n",
            "6188\n",
            "Training accuracy at epoch 1: 0.452488687782805\n",
            "Learning rate is now 0.2997049959000266\n",
            "1m 29s (1 2%) 17.513057124329599\n",
            "39\n",
            "6188\n",
            "Training accuracy at epoch 2: 0.630252100840336\n",
            "Learning rate is now 0.2988211478465144\n",
            "1m 45s (2 4%) 17.476475977635644\n",
            "39\n",
            "6188\n",
            "Training accuracy at epoch 3: 0.630252100840336\n",
            "Learning rate is now 0.297351943983939\n",
            "1m 58s (3 6%) 17.203536543448511\n",
            "31\n",
            "6188\n",
            "Training accuracy at epoch 4: 0.500969618616677\n",
            "Learning rate is now 0.29530318258873034\n",
            "2m 12s (4 8%) 17.893707452933096\n",
            "32\n",
            "6188\n",
            "Training accuracy at epoch 5: 0.517129928894635\n",
            "Learning rate is now 0.2926829491861255\n",
            "2m 31s (5 10%) 18.220393372568378\n",
            "41\n",
            "6188\n",
            "Training accuracy at epoch 6: 0.662572721396251\n",
            "Learning rate is now 0.2895015846402936\n",
            "2m 51s (6 12%) 17.666137281046733\n",
            "27\n",
            "6188\n",
            "Training accuracy at epoch 7: 0.436328377504848\n",
            "Learning rate is now 0.2857716443436699\n",
            "3m 3s (7 14%) 17.669321327727303\n",
            "24\n",
            "6188\n",
            "Training accuracy at epoch 8: 0.387847446670976\n",
            "Learning rate is now 0.2815078486665576\n",
            "3m 17s (8 16%) 17.657213483537948\n",
            "48\n",
            "6188\n",
            "Training accuracy at epoch 9: 0.775694893341952\n",
            "Learning rate is now 0.27672702486255124\n",
            "3m 36s (9 18%) 17.359585052470507\n",
            "32\n",
            "6188\n",
            "Training accuracy at epoch 10: 0.517129928894635\n",
            "Test accuracy: 0.341796875000000\n",
            "Learning rate is now 0.27144804065905465\n",
            "4m 39s (10 20%) 17.011320443329076\n",
            "40\n",
            "6188\n",
            "Training accuracy at epoch 11: 0.646412411118294\n",
            "Learning rate is now 0.26569172979498046\n",
            "4m 55s (11 22%) 16.776038832562772\n",
            "31\n",
            "6188\n",
            "Training accuracy at epoch 12: 0.500969618616677\n",
            "Learning rate is now 0.259480809799501\n",
            "5m 10s (12 24%) 16.675249549752294\n",
            "38\n",
            "6188\n",
            "Training accuracy at epoch 13: 0.614091790562379\n",
            "Learning rate is now 0.25283979233633896\n",
            "5m 25s (13 26%) 16.288980061112486\n",
            "36\n",
            "6188\n",
            "Training accuracy at epoch 14: 0.581771170006464\n",
            "Learning rate is now 0.2457948864674291\n",
            "5m 40s (14 28%) 15.768803582317844\n",
            "32\n",
            "6188\n",
            "Training accuracy at epoch 15: 0.517129928894635\n",
            "Learning rate is now 0.23837389521772476\n",
            "5m 59s (15 30%) 15.597902501407715\n",
            "21\n",
            "6188\n",
            "Training accuracy at epoch 16: 0.339366515837104\n",
            "Learning rate is now 0.23060610584935998\n",
            "6m 11s (16 32%) 15.247248367871789\n",
            "34\n",
            "6188\n",
            "Training accuracy at epoch 17: 0.549450549450549\n",
            "Learning rate is now 0.22252217427820642\n",
            "6m 25s (17 34%) 14.183734797629990\n",
            "38\n",
            "6188\n",
            "Training accuracy at epoch 18: 0.614091790562379\n",
            "Learning rate is now 0.21415400408897836\n",
            "6m 50s (18 36%) 14.267571319205267\n",
            "26\n",
            "6188\n",
            "Training accuracy at epoch 19: 0.420168067226891\n",
            "Learning rate is now 0.20553462062635938\n",
            "7m 6s (19 38%) 13.608685878761060\n",
            "33\n",
            "6188\n",
            "Training accuracy at epoch 20: 0.533290239172592\n",
            "Test accuracy: 0.097656250000000\n",
            "Learning rate is now 0.19669804065905463\n",
            "8m 14s (20 40%) 12.905972027670744\n",
            "40\n",
            "6188\n",
            "Training accuracy at epoch 21: 0.646412411118294\n",
            "Learning rate is now 0.18767913813114576\n",
            "8m 29s (21 42%) 12.618132361305399\n",
            "36\n",
            "6188\n",
            "Training accuracy at epoch 22: 0.581771170006464\n",
            "Learning rate is now 0.17851350653056586\n",
            "8m 41s (22 44%) 12.016087004964245\n",
            "32\n",
            "6188\n",
            "Training accuracy at epoch 23: 0.517129928894635\n",
            "Learning rate is now 0.16923731841786352\n",
            "9m 1s (23 46%) 11.508932911355648\n",
            "33\n",
            "6188\n",
            "Training accuracy at epoch 24: 0.533290239172592\n",
            "Learning rate is now 0.15988718266963237\n",
            "9m 13s (24 48%) 11.007679540415927\n",
            "29\n",
            "6188\n",
            "Training accuracy at epoch 25: 0.468648998060763\n",
            "Learning rate is now 0.1505\n",
            "9m 25s (25 50%) 10.339836944205267\n",
            "48\n",
            "6188\n",
            "Training accuracy at epoch 26: 0.775694893341952\n",
            "Learning rate is now 0.14111281733036765\n",
            "9m 41s (26 52%) 9.836682626025169\n",
            "36\n",
            "6188\n",
            "Training accuracy at epoch 27: 0.581771170006464\n",
            "Learning rate is now 0.13176268158213653\n",
            "9m 59s (27 54%) 9.063257987990870\n",
            "40\n",
            "6188\n",
            "Training accuracy at epoch 28: 0.646412411118294\n",
            "Learning rate is now 0.12248649346943417\n",
            "10m 11s (28 56%) 8.709281512052687\n",
            "33\n",
            "6188\n",
            "Training accuracy at epoch 29: 0.533290239172592\n",
            "Learning rate is now 0.11332086186885419\n",
            "10m 31s (29 57%) 7.874296458367001\n",
            "31\n",
            "6188\n",
            "Training accuracy at epoch 30: 0.500969618616677\n",
            "Test accuracy: 0.537109375000000\n",
            "Learning rate is now 0.1043019593409454\n",
            "11m 19s (30 60%) 7.474114238637913\n",
            "37\n",
            "6188\n",
            "Training accuracy at epoch 31: 0.597931480284421\n",
            "Learning rate is now 0.09546537937364068\n",
            "11m 37s (31 62%) 6.720215297469649\n",
            "35\n",
            "6188\n",
            "Training accuracy at epoch 32: 0.565610859728507\n",
            "Learning rate is now 0.08684599591102163\n",
            "11m 53s (32 64%) 6.180303424423405\n",
            "28\n",
            "6188\n",
            "Training accuracy at epoch 33: 0.452488687782805\n",
            "Learning rate is now 0.07847782572179354\n",
            "12m 8s (33 66%) 5.715342614753984\n",
            "37\n",
            "6188\n",
            "Training accuracy at epoch 34: 0.597931480284421\n",
            "Learning rate is now 0.07039389415063997\n",
            "12m 31s (34 68%) 5.283311544269150\n",
            "28\n",
            "6188\n",
            "Training accuracy at epoch 35: 0.452488687782805\n",
            "Learning rate is now 0.06262610478227527\n",
            "12m 44s (35 70%) 4.682969520534326\n",
            "43\n",
            "6188\n",
            "Training accuracy at epoch 36: 0.694893341952165\n",
            "Learning rate is now 0.05520511353257088\n",
            "13m 1s (36 72%) 4.215640624723823\n",
            "37\n",
            "6188\n",
            "Training accuracy at epoch 37: 0.597931480284421\n",
            "Learning rate is now 0.04816020766366103\n",
            "13m 21s (37 74%) 3.596941478805690\n",
            "38\n",
            "6188\n",
            "Training accuracy at epoch 38: 0.614091790562379\n",
            "Learning rate is now 0.041519190200499004\n",
            "13m 36s (38 76%) 3.208565739716109\n",
            "46\n",
            "6188\n",
            "Training accuracy at epoch 39: 0.743374272786038\n",
            "Learning rate is now 0.035308270205019525\n",
            "13m 51s (39 78%) 2.807164833941765\n",
            "43\n",
            "6188\n",
            "Training accuracy at epoch 40: 0.694893341952165\n",
            "Test accuracy: 0.537109375000000\n",
            "Learning rate is now 0.029551959340945372\n",
            "14m 42s (40 80%) 2.384414396674385\n",
            "38\n",
            "6188\n",
            "Training accuracy at epoch 41: 0.614091790562379\n",
            "Learning rate is now 0.02427297513744878\n",
            "14m 55s (41 82%) 2.067308473987739\n",
            "49\n",
            "6188\n",
            "Training accuracy at epoch 42: 0.791855203619909\n",
            "Learning rate is now 0.019492151333442394\n",
            "15m 10s (42 84%) 1.696484447989683\n",
            "40\n",
            "6188\n",
            "Training accuracy at epoch 43: 0.646412411118294\n",
            "Learning rate is now 0.015228355656330107\n",
            "15m 25s (43 86%) 1.378694106473719\n",
            "53\n",
            "6188\n",
            "Training accuracy at epoch 44: 0.856496444731739\n",
            "Learning rate is now 0.011498415359706422\n",
            "15m 40s (44 88%) 1.073359274293965\n",
            "56\n",
            "6188\n",
            "Training accuracy at epoch 45: 0.904977375565611\n",
            "Learning rate is now 0.008317050813874547\n",
            "15m 56s (45 90%) 0.843500343229051\n",
            "60\n",
            "6188\n",
            "Training accuracy at epoch 46: 0.969618616677440\n",
            "Learning rate is now 0.005696817411269671\n",
            "16m 11s (46 92%) 0.642128461703379\n",
            "52\n",
            "6188\n",
            "Training accuracy at epoch 47: 0.840336134453782\n",
            "Learning rate is now 0.003648056016061036\n",
            "16m 26s (47 94%) 0.475819817033212\n",
            "75\n",
            "6188\n",
            "Training accuracy at epoch 48: 1.212023270846800\n",
            "Learning rate is now 0.0021788521534855743\n",
            "16m 41s (48 96%) 0.358904671499478\n",
            "85\n",
            "6188\n",
            "Training accuracy at epoch 49: 1.373626373626374\n",
            "Test accuracy: 0.781250000000000\n",
            "Learning rate is now 0.001295004099973402\n",
            "17m 12s (49 98%) 0.276827392997323\n",
            "Finish training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[28.97822975203077,\n",
              " 17.5130571243296,\n",
              " 17.476475977635644,\n",
              " 17.20353654344851,\n",
              " 17.893707452933096,\n",
              " 18.220393372568378,\n",
              " 17.666137281046733,\n",
              " 17.669321327727303,\n",
              " 17.657213483537948,\n",
              " 17.359585052470507,\n",
              " 17.011320443329076,\n",
              " 16.776038832562772,\n",
              " 16.675249549752294,\n",
              " 16.288980061112486,\n",
              " 15.768803582317844,\n",
              " 15.597902501407715,\n",
              " 15.247248367871789,\n",
              " 14.18373479762999,\n",
              " 14.267571319205267,\n",
              " 13.60868587876106,\n",
              " 12.905972027670744,\n",
              " 12.618132361305399,\n",
              " 12.016087004964245,\n",
              " 11.508932911355648,\n",
              " 11.007679540415927,\n",
              " 10.339836944205267,\n",
              " 9.83668262602517,\n",
              " 9.06325798799087,\n",
              " 8.709281512052687,\n",
              " 7.8742964583670005,\n",
              " 7.474114238637913,\n",
              " 6.7202152974696485,\n",
              " 6.180303424423405,\n",
              " 5.715342614753984,\n",
              " 5.28331154426915,\n",
              " 4.682969520534326,\n",
              " 4.2156406247238225,\n",
              " 3.59694147880569,\n",
              " 3.208565739716109,\n",
              " 2.8071648339417647,\n",
              " 2.384414396674385,\n",
              " 2.0673084739877394,\n",
              " 1.6964844479896826,\n",
              " 1.3786941064737193,\n",
              " 1.0733592742939648,\n",
              " 0.843500343229051,\n",
              " 0.6421284617033788,\n",
              " 0.47581981703321163,\n",
              " 0.35890467149947797,\n",
              " 0.2768273929973225]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "train(model_enzh, '/content/drive/MyDrive/LING111 autoencoder/enzhautoencoder.txt', '/content/drive/MyDrive/LING111 autoencoder/enzh_nonhidden_weights.pt', 50, optimizer, criterion)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(word_to_index_en[\"can\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvKItkEWUFiS",
        "outputId": "36bcadf6-fe7e-4cdd-a777-dae8f8716720"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "int"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the performance of the model"
      ],
      "metadata": {
        "id": "AQlckKLeSPZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We want to test the model on different word groups\n",
        "# This will let us investigate what kinds of senses the model prefers\n",
        "# as well as how the model is performing in general across word classes\n",
        "\n",
        "# Words that could be nouns but also verbs\n",
        "nounverbs = [\"walk\", \"fly\", \"bat\", \"spring\", \"can\"]\n",
        "\n",
        "# Concrete words\n",
        "concrete = [\"glass\", \"shirt\", \"house\", \"blood\", \"flower\"]\n",
        "\n",
        "# Emotion words\n",
        "emotion = [\"love\", \"hate\", \"happy\", \"confused\", \"angry\"]\n",
        "\n",
        "# Abstract words\n",
        "abstract = [\"democracy\", \"peace\", \"death\", \"fact\", \"being\"]\n",
        "\n",
        "nounverbs_en = []\n",
        "for word in nounverbs:\n",
        "    nounverbs_en.append(word_to_index_en[word])\n",
        "\n",
        "nounverbs_en = torch.tensor(nounverbs_en).to(torch.int64)\n",
        "\n",
        "concrete_en = []\n",
        "for word in concrete:\n",
        "    concrete_en.append(word_to_index_en[word])\n",
        "\n",
        "concrete_en = torch.tensor(concrete_en).to(torch.int64)\n",
        "\n",
        "emotion_en = []\n",
        "for word in emotion:\n",
        "    emotion_en.append(word_to_index_en[word])\n",
        "\n",
        "emotion_en = torch.tensor(emotion_en).to(torch.int64)\n",
        "\n",
        "abstract_en = []\n",
        "for word in abstract:\n",
        "    abstract_en.append(word_to_index_en[word])\n",
        "\n",
        "abstract_en = torch.tensor(abstract_en).to(torch.int64)\n",
        "\n",
        "\n",
        "# maybe different noun/verb classes, or conjunctions?\n",
        "\n",
        "nounclass1 = [\"dog\", \"cat\", \"bird\", \"snake\", \"cow\"]\n",
        "nounclass2 = [\"fire\", \"water\", \"ice\", \"earth\", \"wind\"]\n",
        "verbclass1 = [\"run\", \"jump\", \"swim\", \"speak\", \"talk\"]\n",
        "verbclass2 = [\"be\", \"like\", \"have\", \"do\", \"exist\"]\n",
        "conjunctions = [\"and\", \"but\", \"or\", \"not\", \"both\"]\n",
        "\n",
        "\n",
        "nounclass1_en = []\n",
        "for word in nounclass1:\n",
        "    nounclass1_en.append(word_to_index_en[word])\n",
        "\n",
        "nounclass1_en = torch.tensor(nounclass1_en).to(torch.int64)\n",
        "\n",
        "nounclass2_en = []\n",
        "for word in nounclass2:\n",
        "    nounclass2_en.append(word_to_index_en[word])\n",
        "\n",
        "nounclass2_en = torch.tensor(nounclass2_en).to(torch.int64)\n",
        "\n",
        "verbclass1_en = []\n",
        "for word in verbclass1:\n",
        "    verbclass1_en.append(word_to_index_en[word])\n",
        "\n",
        "verbclass1_en = torch.tensor(verbclass1_en).to(torch.int64)\n",
        "verbclass2_en = []\n",
        "for word in verbclass2:\n",
        "    verbclass2_en.append(word_to_index_en[word])\n",
        "\n",
        "verbclass2_en = torch.tensor(verbclass2_en).to(torch.int64)\n",
        "conjunctions_en = []\n",
        "for word in conjunctions:\n",
        "    conjunctions_en.append(word_to_index_en[word])\n",
        "\n",
        "conjunctions_en = torch.tensor(conjunctions_en).to(torch.int64)\n"
      ],
      "metadata": {
        "id": "l6LjJjNcSXYU"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get model predictions for each of the groups\n",
        "\n",
        "nounverbs_output = model_enzh(nounverbs_en.to(device))\n",
        "concrete_output = model_enzh(concrete_en.to(device))\n",
        "emotion_output = model_enzh(emotion_en.to(device))\n",
        "abstract_output = model_enzh(abstract_en.to(device))\n",
        "nounclass1_output = model_enzh(nounclass1_en.to(device))\n",
        "nounclass2_output = model_enzh(nounclass2_en.to(device))\n",
        "verbclass1_output = model_enzh(verbclass1_en.to(device))\n",
        "verbclass2_output = model_enzh(verbclass2_en.to(device))\n",
        "conjunctions_output = model_enzh(conjunctions_en.to(device))"
      ],
      "metadata": {
        "id": "VM22-A-EUiIL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get index from model predictions\n",
        "\n",
        "nounverbs_index = torch.argmax(TF.softmax(nounverbs_output, dim=1), dim=1)\n",
        "concrete_index = torch.argmax(TF.softmax(concrete_output, dim=1), dim=1)\n",
        "emotion_index = torch.argmax(TF.softmax(emotion_output, dim=1), dim=1)\n",
        "abstract_index = torch.argmax(TF.softmax(abstract_output, dim=1), dim=1)\n",
        "\n",
        "nounclass1_index = torch.argmax(TF.softmax(nounclass1_output, dim=1), dim=1)\n",
        "nounclass2_index = torch.argmax(TF.softmax(nounclass2_output, dim=1), dim=1)\n",
        "verbclass1_index = torch.argmax(TF.softmax(verbclass1_output, dim=1), dim=1)\n",
        "verbclass2_index = torch.argmax(TF.softmax(verbclass2_output, dim=1), dim=1)\n",
        "conjunctions_index = torch.argmax(TF.softmax(conjunctions_output, dim=1), dim=1)"
      ],
      "metadata": {
        "id": "kdnbyEHFU6r7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(nounverbs_en.tolist(), nounverbs_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(concrete_en.tolist(), concrete_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(emotion_en.tolist(), emotion_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(abstract_en.tolist(), abstract_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(nounclass1_en.tolist(), nounclass1_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(nounclass2_en.tolist(), nounclass2_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(verbclass1_en.tolist(), verbclass1_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(verbclass2_en.tolist(), verbclass2_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n",
        "\n",
        "for i, j in zip(conjunctions_en.tolist(), conjunctions_index.tolist()):\n",
        "    print(f\"{vocab_en[i]} & {vocab_zh[j]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RRn_BJuVhHH",
        "outputId": "3d6cab76-0d2a-45fc-fbbb-783a7ed96f6b"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "walk & 320路\n",
            "fly & 进\n",
            "bat & 糖稀\n",
            "spring & 3\n",
            "can & 需要\n",
            "glass & 新生彩票\n",
            "shirt & 衬衣\n",
            "house & 修械所\n",
            "blood & 血管\n",
            "flower & 蝴蝶\n",
            "love & 点开后\n",
            "hate & 小幅收涨\n",
            "happy & 目前的战绩\n",
            "confused & 回信息\n",
            "angry & 根本不认识\n",
            "democracy & 独裁国家\n",
            "peace & 门户\n",
            "death & 封神榜2\n",
            "fact & ·\n",
            "being & 二十七名\n",
            "dog & 战斗宠物\n",
            "cat & 好带\n",
            "bird & 鸟儿\n",
            "snake & 捕兽夹\n",
            "cow & 年总产值\n",
            "fire & 小学三年级日记300字\n",
            "water & ===\n",
            "ice & ===\n",
            "earth & 星球\n",
            "wind & 经济发展方式\n",
            "run & 进\n",
            "jump & 哪段\n",
            "swim & 高二日记二十篇\n",
            "speak & 看到\n",
            "talk & 500m\n",
            "be & 2.68\n",
            "like & 啊\n",
            "have & 两年\n",
            "do & 要说\n",
            "exist & 搞错\n",
            "and & 和\n",
            "but & 啊\n",
            "or & 只限于\n",
            "not & 3000\n",
            "both & 和\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}